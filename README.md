# RAG Telegram Bot с графовой базой знаний
Проект представляет собой Telegram-бота, который отвечает на вопросы о вселенной Warhammer 40k с использованием Retrieval-Augmented Generation (RAG). 
Бот комбинирует поиск по векторному хранилищу документов и графовый анализ для генерации информативных ответов. 
Графовая база Neo4j используется для фильтрации нерелевантных фрагментов, поиска дополнительных релевантных чанков и обогащения контекста за счёт связей между фрагментами.

**Основные возможности:**
- Разделение сложных вопросов на под-вопросы и извлечение ключевых сущностей.
- Поиск релевантных документов в **Chroma-векторном хранилище** по под-вопросам и сущностям.
- Фильтрация нерелевантных чанков и поиск дополнительных релевантных фрагментов с обогащением контекста за счёт связей сущностей в **графовой базе Neo4j**.
- Генерация текстового ответа с использованием **LLM** с учётом найденного контекста.
- Отправка форматированных ответов пользователю через **Telegram**, включая источники информации.
- **Дообучение модели** эмбеддингов на кастомном датасете для более точного поиска релевантных документов.
- Создание и подготовка **собственного датасета** для генерации эмбеддингов, адаптированного под специфику данных.


### **Общий пайплайн**

* Пользователь отправляет вопрос в Telegram.
* Вопрос разбивается на под-вопросы, извлекаются ключевые сущности.
* Ретривер ищет релевантные документы в Chroma-векторном хранилище.
* **Графовая база**:
  * фильтрует нерелевантные фрагменты,
  * ищет дополнительные релевантные узлы,
  * добавляет контекст о взаимосвязях между чанками.
* LLM генерирует финальный ответ с учётом найденного контекста.
* Ответ форматируется и отправляется пользователю через Telegram.

<img width="1247" height="654" alt="RAG drawio(1)" src="https://github.com/user-attachments/assets/41b7fafb-d4db-46c8-930e-79192051eaab" />

### **Технологический стек**

* **Язык и фреймворки:** Python, aiogram.
* **RAG:** LangChain.
* **Векторное хранилище:** Chroma.
* **Генерация эмбеддингов:** sentence-transformers.
* **LLM:** GigaChat.
* **Графовая база:** Neo4j.
* **Docker:** контейнеризация.


### **Источник и подготовка данных:**
* Данные собирались с **Warhammer 40k Fandom** с помощью парсера на Python.
* Статьи сохраняются в **SQLite базу**.
* Из текстов извлекаются источники и ключевые ссылки между сущностями для последующего использования в графовой базе.
* Тексты статей делятся на семантически осмысленные фрагменты (чанки).

### **Дообучение (fine-tuning) модели эмбеддингов**
* Для каждого чанка с помощью LLM (**GigaChat**) генерировались 4 вопроса, покрывающих факты и объяснения из фрагмента, в формате JSON.
* Результаты сохранялись в базе данных SQLite.
* Использовалась предобученная модель **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2**.
* Дообучение проводилось на сгенерированных парах «чанк — вопрос».
* После дообучения эмбеддинги интегрировались в **Chroma**, что повышало точность поиска и качество генерации в RAG-пайплайне.



